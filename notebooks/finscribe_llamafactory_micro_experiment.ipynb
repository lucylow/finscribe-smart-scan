{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FinScribe LLaMA-Factory Micro LoRA Experiment\n",
    "\n",
    "This notebook runs a tiny LoRA SFT with LLaMA-Factory on 10 synthetic invoice pairs for development/testing.\n",
    "\n",
    "**Requirements:**\n",
    "- Colab with GPU runtime (recommended)\n",
    "- Hugging Face token (if using gated models)\n",
    "- ~20GB disk space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Setup & Install\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab cell 1: install deps & clone\n",
    "# If you run into space issues, consider mounting Google Drive\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def run_command(cmd, check=True, shell=True):\n",
    "    \"\"\"Run a shell command with error handling.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(cmd, shell=shell, check=check, \n",
    "                              capture_output=True, text=True)\n",
    "        if result.stdout:\n",
    "            print(result.stdout)\n",
    "        return result.returncode == 0\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚ùå Error running command: {cmd}\")\n",
    "        print(f\"Error output: {e.stderr}\")\n",
    "        if check:\n",
    "            raise\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Unexpected error: {e}\")\n",
    "        if check:\n",
    "            raise\n",
    "        return False\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"Checking GPU availability...\")\n",
    "run_command(\"nvidia-smi\", check=False)\n",
    "\n",
    "# Clone LLaMA-Factory if not already present\n",
    "if os.path.exists(\"LLaMA-Factory\"):\n",
    "    print(\"‚ö†Ô∏è  LLaMA-Factory directory already exists. Skipping clone.\")\n",
    "    print(\"   If you want a fresh clone, delete the directory first.\")\n",
    "else:\n",
    "    print(\"Cloning LLaMA-Factory repository...\")\n",
    "    if not run_command(\"git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\"):\n",
    "        raise RuntimeError(\"Failed to clone LLaMA-Factory repository\")\n",
    "\n",
    "# Change to LLaMA-Factory directory\n",
    "if not os.path.exists(\"LLaMA-Factory\"):\n",
    "    raise RuntimeError(\"LLaMA-Factory directory not found after clone\")\n",
    "    \n",
    "os.chdir(\"LLaMA-Factory\")\n",
    "print(f\"‚úÖ Changed to directory: {os.getcwd()}\")\n",
    "\n",
    "# Install dependencies\n",
    "print(\"Installing LLaMA-Factory dependencies (this may take several minutes)...\")\n",
    "if not run_command('pip install -e \".[torch,metrics]\"'):\n",
    "    print(\"‚ö†Ô∏è  Installation failed. You may need to:\")\n",
    "    print(\"   - Check your CUDA/PyTorch compatibility\")\n",
    "    print(\"   - Ensure you have sufficient disk space\")\n",
    "    print(\"   - Try: pip install -e '.[torch,metrics]' manually\")\n",
    "    raise RuntimeError(\"Failed to install LLaMA-Factory dependencies\")\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Create Tiny Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab cell 2: Create synthetic invoice dataset\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    # Create data directory with error handling\n",
    "    data_dir = Path(\"data\")\n",
    "    data_dir.mkdir(exist_ok=True)\n",
    "    print(f\"‚úÖ Data directory ready: {data_dir.absolute()}\")\n",
    "    \n",
    "    train = []\n",
    "    \n",
    "    # Generate training examples with validation\n",
    "    print(\"Generating synthetic invoice examples...\")\n",
    "    for i in range(10):\n",
    "        try:\n",
    "            vendor = random.choice([\"TechCorp Inc.\", \"Acme LLC\", \"Globex\"])\n",
    "            inv = f\"INV-{1000+i}\"\n",
    "            date = f\"2024-0{random.randint(1,9)}-{random.randint(10,28)}\"\n",
    "            prompt = f\"Validate and correct: OCR_TEXT: Vendor: {vendor} Invoice: {inv} Date: {date} Items: Widget 2x50 Total 100\"\n",
    "            \n",
    "            # Validate JSON structure before adding\n",
    "            completion_data = {\n",
    "                \"document_type\": \"invoice\",\n",
    "                \"vendor\": {\"name\": vendor},\n",
    "                \"client\": {},\n",
    "                \"line_items\": [{\"desc\": \"Widget\", \"qty\": 2, \"unit_price\": 50.0, \"line_total\": 100.0}],\n",
    "                \"financial_summary\": {\"subtotal\": 100.0, \"tax_rate\": 0.0, \"tax_amount\": 0.0, \"grand_total\": 100.0}\n",
    "            }\n",
    "            \n",
    "            # Validate JSON serialization\n",
    "            completion_json = json.dumps(completion_data)\n",
    "            json.loads(completion_json)  # Verify it's valid JSON\n",
    "            \n",
    "            train.append({\n",
    "                \"instruction\": \"Validate and return JSON only\",\n",
    "                \"input\": prompt,\n",
    "                \"output\": completion_json\n",
    "            })\n",
    "        except (ValueError, KeyError, TypeError) as e:\n",
    "            print(f\"‚ö†Ô∏è  Error creating example {i}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if len(train) == 0:\n",
    "        raise RuntimeError(\"Failed to create any training examples\")\n",
    "    \n",
    "    # Write dataset file with error handling\n",
    "    output_file = data_dir / \"finscribe_lf_train.jsonl\"\n",
    "    try:\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            for item in train:\n",
    "                # Validate each item before writing\n",
    "                if not all(key in item for key in [\"instruction\", \"input\", \"output\"]):\n",
    "                    raise ValueError(f\"Invalid item structure: {item}\")\n",
    "                f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "        \n",
    "        # Verify file was created and has content\n",
    "        if not output_file.exists():\n",
    "            raise FileNotFoundError(f\"Output file was not created: {output_file}\")\n",
    "        \n",
    "        file_size = output_file.stat().st_size\n",
    "        if file_size == 0:\n",
    "            raise ValueError(f\"Output file is empty: {output_file}\")\n",
    "        \n",
    "        print(f\"‚úÖ Successfully wrote {len(train)} examples to {output_file}\")\n",
    "        print(f\"   File size: {file_size} bytes\")\n",
    "        \n",
    "        # Validate file by reading it back\n",
    "        with open(output_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            if len(lines) != len(train):\n",
    "                raise ValueError(f\"Line count mismatch: expected {len(train)}, got {len(lines)}\")\n",
    "            # Validate JSON on first line\n",
    "            json.loads(lines[0])\n",
    "        \n",
    "        print(\"‚úÖ Dataset file validated successfully\")\n",
    "        \n",
    "    except OSError as e:\n",
    "        raise RuntimeError(f\"Failed to write dataset file: {e}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(f\"Invalid JSON in dataset: {e}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Unexpected error creating dataset: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in dataset creation: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Register Dataset & Create Training Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab cell 3: Register dataset and create YAML config\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    # Validate that dataset file exists before registering\n",
    "    dataset_file = Path(\"data/finscribe_lf_train.jsonl\")\n",
    "    if not dataset_file.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Dataset file not found: {dataset_file}\\n\"\n",
    "            \"Please run the previous cell to create the dataset first.\"\n",
    "        )\n",
    "    \n",
    "    print(f\"‚úÖ Found dataset file: {dataset_file}\")\n",
    "    \n",
    "    # Register dataset in dataset_info.json\n",
    "    dataset_info_path = Path(\"data/dataset_info.json\")\n",
    "    \n",
    "    # Load existing dataset_info if it exists\n",
    "    existing_info = {}\n",
    "    if dataset_info_path.exists():\n",
    "        try:\n",
    "            with open(dataset_info_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                existing_info = json.load(f)\n",
    "            print(f\"‚úÖ Loaded existing dataset_info.json with {len(existing_info)} entries\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"‚ö†Ô∏è  Existing dataset_info.json is invalid JSON: {e}\")\n",
    "            print(\"   Creating new file...\")\n",
    "            existing_info = {}\n",
    "    \n",
    "    # Add or update our dataset entry\n",
    "    dataset_info = {\n",
    "        \"finscribe_lf_train\": {\n",
    "            \"file_name\": \"finscribe_lf_train.jsonl\",\n",
    "            \"format\": \"jsonl\",\n",
    "            \"description\": \"FinScribe micro experiment dataset\"\n",
    "        }\n",
    "    }\n",
    "    existing_info.update(dataset_info)\n",
    "    \n",
    "    # Write dataset_info.json with error handling\n",
    "    try:\n",
    "        with open(dataset_info_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(existing_info, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"‚úÖ Registered dataset in {dataset_info_path}\")\n",
    "        \n",
    "        # Validate the written JSON\n",
    "        with open(dataset_info_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            json.load(f)\n",
    "        print(\"‚úÖ Dataset info file validated\")\n",
    "        \n",
    "    except OSError as e:\n",
    "        raise RuntimeError(f\"Failed to write dataset_info.json: {e}\")\n",
    "    except json.JSONEncodeError as e:\n",
    "        raise ValueError(f\"Failed to encode dataset_info as JSON: {e}\")\n",
    "    \n",
    "    # Create training YAML\n",
    "    yaml_config = \"\"\"model_name_or_path: <SMALL_MODEL_NAME>  # Replace with small model like 'facebook/opt-125m' or 'microsoft/phi-2'\n",
    "stage: sft\n",
    "finetuning_type: lora\n",
    "dataset: finscribe_lf_train\n",
    "cutoff_len: 512\n",
    "output_dir: saves/finscribe_test\n",
    "per_device_train_batch_size: 1\n",
    "num_train_epochs: 1\n",
    "learning_rate: 2e-5\n",
    "bf16: false\n",
    "logging_steps: 5\n",
    "save_steps: 10\n",
    "\"\"\"\n",
    "    \n",
    "    # Create output directory\n",
    "    yaml_dir = Path(\"examples/train_lora\")\n",
    "    try:\n",
    "        yaml_dir.mkdir(parents=True, exist_ok=True)\n",
    "    except OSError as e:\n",
    "        raise RuntimeError(f\"Failed to create directory {yaml_dir}: {e}\")\n",
    "    \n",
    "    # Write YAML config file\n",
    "    yaml_file = yaml_dir / \"finscribe_colab.yaml\"\n",
    "    try:\n",
    "        with open(yaml_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(yaml_config.strip())\n",
    "        \n",
    "        # Verify file was created\n",
    "        if not yaml_file.exists():\n",
    "            raise FileNotFoundError(f\"YAML file was not created: {yaml_file}\")\n",
    "        \n",
    "        print(f\"‚úÖ Created training config: {yaml_file}\")\n",
    "        \n",
    "        # Check if model name needs to be replaced\n",
    "        with open(yaml_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "            if \"<SMALL_MODEL_NAME>\" in content:\n",
    "                print(\"\\n‚ö†Ô∏è  IMPORTANT: Edit the YAML file to replace <SMALL_MODEL_NAME> with your chosen model!\")\n",
    "                print(f\"   File location: {yaml_file.absolute()}\")\n",
    "                print(\"   Suggested models: 'facebook/opt-125m' or 'microsoft/phi-2'\")\n",
    "            else:\n",
    "                print(\"‚úÖ Model name appears to be configured\")\n",
    "                \n",
    "    except OSError as e:\n",
    "        raise RuntimeError(f\"Failed to write YAML config file: {e}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå File not found: {e}\")\n",
    "    raise\n",
    "except (ValueError, RuntimeError) as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Unexpected error: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Run Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab cell 4: Run training\n",
    "# Make sure you've edited the YAML to set model_name_or_path\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def validate_training_config():\n",
    "    \"\"\"Validate that the training configuration is ready.\"\"\"\n",
    "    yaml_file = Path(\"examples/train_lora/finscribe_colab.yaml\")\n",
    "    \n",
    "    if not yaml_file.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Training config not found: {yaml_file}\\n\"\n",
    "            \"Please run the previous cell to create the config first.\"\n",
    "        )\n",
    "    \n",
    "    # Check if model name is still a placeholder\n",
    "    with open(yaml_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "        if \"<SMALL_MODEL_NAME>\" in content:\n",
    "            raise ValueError(\n",
    "                \"Model name not configured!\\n\"\n",
    "                f\"Please edit {yaml_file} and replace <SMALL_MODEL_NAME> with a valid model name.\\n\"\n",
    "                \"Suggested: 'facebook/opt-125m' or 'microsoft/phi-2'\"\n",
    "            )\n",
    "    \n",
    "    # Verify dataset exists\n",
    "    dataset_file = Path(\"data/finscribe_lf_train.jsonl\")\n",
    "    if not dataset_file.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Dataset file not found: {dataset_file}\\n\"\n",
    "            \"Please run the dataset creation cell first.\"\n",
    "        )\n",
    "    \n",
    "    print(\"‚úÖ Training configuration validated\")\n",
    "\n",
    "try:\n",
    "    # Validate configuration before training\n",
    "    print(\"Validating training configuration...\")\n",
    "    validate_training_config()\n",
    "    \n",
    "    # Check if LLaMA-Factory is installed\n",
    "    try:\n",
    "        import llamafactory\n",
    "        print(f\"‚úÖ LLaMA-Factory found: {llamafactory.__file__}\")\n",
    "    except ImportError:\n",
    "        raise ImportError(\n",
    "            \"LLaMA-Factory not installed. Please run the setup cell first.\"\n",
    "        )\n",
    "    \n",
    "    yaml_file = \"examples/train_lora/finscribe_colab.yaml\"\n",
    "    print(f\"\\nüöÄ Starting training with config: {yaml_file}\")\n",
    "    print(\"   This may take several minutes...\")\n",
    "    \n",
    "    # Try Python module first (more reliable)\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [sys.executable, \"-m\", \"llamafactory.entrypoints\", \"train\", yaml_file],\n",
    "            check=False,  # Don't raise on non-zero exit\n",
    "            capture_output=False  # Show output in real-time\n",
    "        )\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            print(f\"\\n‚ùå Training failed with exit code {result.returncode}\")\n",
    "            print(\"   Check the output above for error details.\")\n",
    "            raise subprocess.CalledProcessError(result.returncode, result.args)\n",
    "        \n",
    "        print(\"\\n‚úÖ Training completed successfully!\")\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n‚ùå Training command failed: {e}\")\n",
    "        print(\"\\nTroubleshooting tips:\")\n",
    "        print(\"  - Check that the model name in the YAML is valid and accessible\")\n",
    "        print(\"  - Ensure you have sufficient GPU memory\")\n",
    "        print(\"  - Verify the dataset file is valid JSONL\")\n",
    "        print(\"  - Check disk space for output directory\")\n",
    "        raise\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚ö†Ô∏è  Training interrupted by user\")\n",
    "        raise\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Unexpected error during training: {e}\")\n",
    "        raise\n",
    "\n",
    "except (FileNotFoundError, ValueError, ImportError) as e:\n",
    "    print(f\"‚ùå Configuration error: {e}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Inference Test (if serving locally)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab cell 5: Example inference stub\n",
    "# Use your running LLaMA-Factory API or load model directly\n",
    "import requests\n",
    "import json\n",
    "from typing import Optional, Dict, Any\n",
    "import time\n",
    "\n",
    "def test_api_connection(api_url: str, timeout: int = 5) -> bool:\n",
    "    \"\"\"Test if API server is reachable.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(api_url.replace(\"/v1/chat/completions\", \"/health\"), \n",
    "                              timeout=timeout)\n",
    "        return response.status_code == 200\n",
    "    except (requests.exceptions.RequestException, AttributeError):\n",
    "        return False\n",
    "\n",
    "def call_inference_api(\n",
    "    api_url: str,\n",
    "    model_name: str,\n",
    "    prompt: str,\n",
    "    temperature: float = 0.0,\n",
    "    timeout: int = 30,\n",
    "    max_retries: int = 3\n",
    ") -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Call the inference API with error handling and retries.\"\"\"\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": temperature\n",
    "    }\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"Attempting API call (attempt {attempt + 1}/{max_retries})...\")\n",
    "            response = requests.post(\n",
    "                api_url,\n",
    "                json=payload,\n",
    "                timeout=timeout,\n",
    "                headers={\"Content-Type\": \"application/json\"}\n",
    "            )\n",
    "            \n",
    "            # Check HTTP status\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Validate response is JSON\n",
    "            try:\n",
    "                result = response.json()\n",
    "                return result\n",
    "            except json.JSONDecodeError as e:\n",
    "                raise ValueError(f\"API returned invalid JSON: {e}\\nResponse text: {response.text[:200]}\")\n",
    "                \n",
    "        except requests.exceptions.Timeout:\n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = (attempt + 1) * 2\n",
    "                print(f\"‚ö†Ô∏è  Request timed out. Retrying in {wait_time} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "            else:\n",
    "                raise RuntimeError(f\"API request timed out after {max_retries} attempts\")\n",
    "                \n",
    "        except requests.exceptions.ConnectionError:\n",
    "            raise ConnectionError(\n",
    "                f\"Cannot connect to API at {api_url}\\n\"\n",
    "                \"Make sure the LLaMA-Factory API server is running.\\n\"\n",
    "                \"Start it with: llamafactory-cli api\"\n",
    "            )\n",
    "            \n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if e.response.status_code == 404:\n",
    "                raise FileNotFoundError(\n",
    "                    f\"API endpoint not found: {api_url}\\n\"\n",
    "                    \"Check that the API server is running and the endpoint is correct.\"\n",
    "                )\n",
    "            elif e.response.status_code == 503:\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = (attempt + 1) * 2\n",
    "                    print(f\"‚ö†Ô∏è  Service unavailable. Retrying in {wait_time} seconds...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "                else:\n",
    "                    raise RuntimeError(\"API service unavailable after retries\")\n",
    "            else:\n",
    "                raise RuntimeError(\n",
    "                    f\"API returned error {e.response.status_code}: {e.response.text[:200]}\"\n",
    "                )\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            raise RuntimeError(f\"Request failed: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Configuration\n",
    "API_BASE = \"http://localhost:8000\"\n",
    "API_URL = f\"{API_BASE}/v1/chat/completions\"\n",
    "MODEL_NAME = \"finscribe-llama\"  # Update this to match your trained model name\n",
    "\n",
    "# Example prompt\n",
    "test_prompt = (\n",
    "    \"Validate JSON: {\\\"document_type\\\":\\\"invoice\\\",\"\n",
    "    \"\\\"vendor\\\":{\\\"name\\\":\\\"TechCorp Inc.\\\"},\"\n",
    "    \"\\\"line_items\\\":[{\\\"desc\\\":\\\"Widget\\\",\\\"qty\\\":2,\\\"unit_price\\\":50.0}]}\"\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Inference API Test\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Test API connection\n",
    "    print(f\"Testing connection to {API_BASE}...\")\n",
    "    if test_api_connection(API_URL):\n",
    "        print(\"‚úÖ API server is reachable\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Health check endpoint not available, but continuing...\")\n",
    "    \n",
    "    # Make inference call\n",
    "    print(f\"\\nCalling inference API...\")\n",
    "    print(f\"  URL: {API_URL}\")\n",
    "    print(f\"  Model: {MODEL_NAME}\")\n",
    "    print(f\"  Prompt: {test_prompt[:50]}...\")\n",
    "    \n",
    "    result = call_inference_api(\n",
    "        api_url=API_URL,\n",
    "        model_name=MODEL_NAME,\n",
    "        prompt=test_prompt,\n",
    "        temperature=0.0,\n",
    "        timeout=30\n",
    "    )\n",
    "    \n",
    "    if result:\n",
    "        print(\"\\n‚úÖ API call successful!\")\n",
    "        print(\"\\nResponse:\")\n",
    "        print(json.dumps(result, indent=2, ensure_ascii=False))\n",
    "        \n",
    "        # Extract and validate response content\n",
    "        if \"choices\" in result and len(result[\"choices\"]) > 0:\n",
    "            content = result[\"choices\"][0].get(\"message\", {}).get(\"content\", \"\")\n",
    "            if content:\n",
    "                print(f\"\\nGenerated content:\\n{content}\")\n",
    "                # Try to parse as JSON if it looks like JSON\n",
    "                if content.strip().startswith(\"{\"):\n",
    "                    try:\n",
    "                        parsed = json.loads(content)\n",
    "                        print(\"‚úÖ Response is valid JSON\")\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(\"‚ö†Ô∏è  Response is not valid JSON\")\n",
    "    else:\n",
    "        print(\"‚ùå API call returned no result\")\n",
    "        \n",
    "except ConnectionError as e:\n",
    "    print(f\"\\n‚ùå Connection error: {e}\")\n",
    "    print(\"\\nTo start the API server, run:\")\n",
    "    print(\"  llamafactory-cli api\")\n",
    "    print(\"  # or\")\n",
    "    print(\"  python -m llamafactory.entrypoints api\")\n",
    "    \n",
    "except (FileNotFoundError, ValueError, RuntimeError) as e:\n",
    "    print(f\"\\n‚ùå Error: {e}\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚ö†Ô∏è  Interrupted by user\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Unexpected error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}