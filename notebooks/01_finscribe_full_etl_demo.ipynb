{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FinScribe ETL Pipeline - Full Demo\n",
        "\n",
        "This notebook demonstrates the complete ETL pipeline for financial document processing:\n",
        "\n",
        "1. **Extract**: Ingest documents from various sources\n",
        "2. **Transform**: OCR, semantic parsing, normalization\n",
        "3. **Load**: Store structured data in PostgreSQL + MinIO\n",
        "4. **Validate**: Business rule validation\n",
        "\n",
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q opencv-python pillow psycopg2-binary dateparser requests boto3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone repo (if not already cloned)\n",
        "import os\n",
        "if not os.path.exists('finscribe-smart-scan'):\n",
        "    !git clone https://github.com/lucylow/finscribe-smart-scan.git\n",
        "    %cd finscribe-smart-scan\n",
        "else:\n",
        "    %cd finscribe-smart-scan\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import ETL Pipeline Modules\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '.')\n",
        "\n",
        "from data_pipeline.ingestion import ingest_from_local\n",
        "from data_pipeline.preprocess import preprocess\n",
        "from data_pipeline.ocr_client import run_ocr\n",
        "from data_pipeline.semantic_parser import parse\n",
        "from data_pipeline.normalizer import normalize_invoice_data\n",
        "from data_pipeline.validator import validate\n",
        "\n",
        "print(\"ETL modules imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run ETL Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process a single invoice\n",
        "invoice_path = \"examples/sample_invoice_1.png\"\n",
        "\n",
        "if not os.path.exists(invoice_path):\n",
        "    print(f\"Invoice not found: {invoice_path}\")\n",
        "    print(\"Please add a sample invoice to the examples/ directory\")\n",
        "else:\n",
        "    print(f\"Processing: {invoice_path}\")\n",
        "    \n",
        "    # Extract\n",
        "    print(\"\\n[1/5] Ingesting...\")\n",
        "    src = ingest_from_local(invoice_path)\n",
        "    \n",
        "    print(\"\\n[2/5] Preprocessing...\")\n",
        "    clean = preprocess(src)\n",
        "    \n",
        "    print(\"\\n[3/5] Running OCR...\")\n",
        "    ocr_result = run_ocr(clean)\n",
        "    \n",
        "    print(\"\\n[4/5] Parsing semantic structure...\")\n",
        "    parsed = parse(ocr_result)\n",
        "    normalized = normalize_invoice_data(parsed)\n",
        "    \n",
        "    print(\"\\n[5/5] Validating...\")\n",
        "    validation = validate(normalized)\n",
        "    \n",
        "    print(\"\\nâœ… ETL Pipeline Complete!\")\n",
        "    print(f\"Validation: {'PASSED' if validation['ok'] else 'FAILED'}\")\n",
        "    if not validation['ok']:\n",
        "        print(f\"Errors: {validation['errors']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pprint import pprint\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"RAW OCR TEXT (first 500 chars):\")\n",
        "print(\"=\" * 60)\n",
        "if 'ocr_result' in locals():\n",
        "    print(ocr_result.get(\"text\", \"\")[:500])\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STRUCTURED JSON:\")\n",
        "print(\"=\" * 60)\n",
        "if 'normalized' in locals():\n",
        "    print(json.dumps(normalized, indent=2))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
